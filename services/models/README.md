# ğŸ§  Service Training - Vietnam Energy Forecasting

## ğŸ“‹ Overview

Service Training lÃ  thÃ nh pháº§n thá»© 3 trong pipeline, chá»‹u trÃ¡ch nhiá»‡m train ML models Ä‘á»ƒ dá»± bÃ¡o tiÃªu thá»¥ Ä‘iá»‡n.

**Input**: Dá»¯ liá»‡u features tá»« S3 Gold Layer  
**Output**: 
- Trained models (S3 Models bucket)
- Model metadata & metrics
- Predictions for Dashboard

---

## ğŸ¯ Key Features

### âœ… Model Agnostic Architecture
- Abstract base class cho táº¥t cáº£ models
- Dá»… dÃ ng thÃªm model má»›i (LSTM, Prophet, Random Forest)
- Factory pattern Ä‘á»ƒ switch models

### âœ… Standardized Output
```python
{
  "predictions": [100.5, 105.2, ...],
  "confidence_intervals": {"lower": [...], "upper": [...]},
  "feature_importance": {"temperature": 0.25, ...},
  "metadata": {"model_type": "xgboost", "version": "v1.0.0", ...}
}
```

### âœ… Model Versioning
```
models/xgboost/
â”œâ”€â”€ v1.0.0/ â†’ model.pkl, metadata.json, metrics.json
â”œâ”€â”€ v1.1.0/
â””â”€â”€ latest/ â†’ symlink to best version
```

### âœ… Comprehensive Evaluation
- **Metrics**: RMSE, MAPE, MAE, RÂ², Forecast Bias
- **Cross-validation**: Time-series aware CV
- **Feature importance**: Top features analysis
- **Overfitting detection**: Train/val comparison

---

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ main.py                  # ğŸ Entry point
â”œâ”€â”€ config.py                # âš™ï¸ Configuration
â”‚
â”œâ”€â”€ data/                    # ğŸ“Š Data handling
â”‚   â”œâ”€â”€ loader.py           # Load from S3 Gold
â”‚   â”œâ”€â”€ preprocessor.py     # Feature selection, scaling
â”‚   â””â”€â”€ splitter.py         # Train/val/test split
â”‚
â”œâ”€â”€ models/                  # ğŸ¤– Model implementations
â”‚   â”œâ”€â”€ base_model.py       # Abstract base class
â”‚   â”œâ”€â”€ xgboost_model.py    # XGBoost implementation
â”‚   â””â”€â”€ model_factory.py    # Factory pattern
â”‚
â”œâ”€â”€ training/                # ğŸ‹ï¸ Training logic
â”‚   â”œâ”€â”€ trainer.py          # Training pipeline
â”‚   â”œâ”€â”€ hyperparameter.py   # Hyperparameter tuning
â”‚   â””â”€â”€ callbacks.py        # Training callbacks
â”‚
â”œâ”€â”€ evaluation/              # ğŸ“ˆ Evaluation
â”‚   â”œâ”€â”€ metrics.py          # RMSE, MAPE, MAE, RÂ²
â”‚   â””â”€â”€ validator.py        # Cross-validation
â”‚
â””â”€â”€ storage/                 # ğŸ’¾ Model storage
    â”œâ”€â”€ model_registry.py   # S3 versioning
    â””â”€â”€ metadata.py         # Metadata management
```

---

## ğŸš€ Quick Start

### Local Development

```bash
cd services/training
pip install -r requirements.txt

# Setup environment
cp .env.example .env
# Edit .env with S3 bucket name

# Run training
MODE=FULL_TRAIN python src/main.py
```

### Docker

```bash
docker build -t vietnam-energy-training:latest .

docker run --rm \
  -e MODE=FULL_TRAIN \
  -e MODEL_TYPE=xgboost \
  -e S3_BUCKET=vietnam-energy-data \
  -e AWS_ACCESS_KEY_ID=xxx \
  -e AWS_SECRET_ACCESS_KEY=xxx \
  vietnam-energy-training:latest
```

---

## âš™ï¸ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `MODE` | Training mode: `FULL_TRAIN`, `INCREMENTAL`, `PREDICT` | `FULL_TRAIN` |
| `MODEL_TYPE` | Model type: `xgboost`, `lstm`, etc. | `xgboost` |
| `S3_BUCKET` | S3 bucket name | `vietnam-energy-data` |
| `MODEL_VERSION` | Model version (auto if not set) | Auto-generated |
| `LOG_LEVEL` | Logging level | `INFO` |

### Execution Modes

#### 1. FULL_TRAIN (Weekly)
- Load toÃ n bá»™ Gold data
- Train tá»« Ä‘áº§u
- Hyperparameter tuning (optional)
- Save new model version

#### 2. INCREMENTAL (Future)
- Load existing model
- Fine-tune vá»›i data má»›i
- Update model

#### 3. PREDICT (Daily)
- Load latest model
- Generate predictions
- Save for Dashboard

---

## ğŸ“Š Training Pipeline

```
1. LOAD DATA
   â”œâ”€ Load Gold features from S3
   â”œâ”€ Validate schema
   â””â”€ Prepare X, y

2. SPLIT DATA
   â”œâ”€ Train: 70%
   â”œâ”€ Validation: 15%
   â””â”€ Test: 15%

3. TRAIN MODEL
   â”œâ”€ Initialize XGBoost
   â”œâ”€ Train vá»›i early stopping
   â””â”€ Cross-validation (optional)

4. EVALUATE
   â”œâ”€ Calculate metrics (RMSE, MAPE, MAE, RÂ²)
   â”œâ”€ Feature importance
   â””â”€ Confidence intervals

5. SAVE MODEL
   â”œâ”€ Save model.pkl
   â”œâ”€ Save metadata.json
   â”œâ”€ Save metrics.json
   â””â”€ Update latest/
```

---

## ğŸ“ˆ Metrics

### Regression Metrics
- **RMSE** (Root Mean Square Error): Äá»™ lá»‡ch trung bÃ¬nh
- **MAPE** (Mean Absolute Percentage Error): % lá»‡ch
- **MAE** (Mean Absolute Error): Sai sá»‘ tuyá»‡t Ä‘á»‘i
- **RÂ²** (R-squared): Äá»™ fit cá»§a model

### Time-Series Specific
- **Forecast Bias**: Xu hÆ°á»›ng over/under predict
- **Coverage**: % predictions trong CI
- **Direction Accuracy**: % dá»± Ä‘oÃ¡n Ä‘Ãºng hÆ°á»›ng

---

## ğŸ›ï¸ Hyperparameter Tuning

### Grid Search

```python
param_grid = {
    'max_depth': [3, 6, 9],
    'learning_rate': [0.01, 0.1, 0.3],
    'n_estimators': [50, 100, 200]
}

tuner = HyperparameterTuner(XGBoostModel, metric='rmse')
best_params, best_score = tuner.grid_search(
    param_grid, X_train, y_train, X_val, y_val
)
```

### Random Search

```python
param_distributions = {
    'max_depth': (3, 10),
    'learning_rate': (0.01, 0.3),
    'n_estimators': (50, 200)
}

best_params, best_score = tuner.random_search(
    param_distributions, X_train, y_train, X_val, y_val, n_trials=20
)
```

---

## ğŸ’¾ Model Storage

### S3 Structure

```
models/
â”œâ”€â”€ xgboost/
â”‚   â”œâ”€â”€ v1.0.0/
â”‚   â”‚   â”œâ”€â”€ model.pkl          # Trained model
â”‚   â”‚   â”œâ”€â”€ metadata.json      # Model metadata
â”‚   â”‚   â””â”€â”€ metrics.json       # Performance metrics
â”‚   â”œâ”€â”€ v1.1.0/
â”‚   â””â”€â”€ latest/                # Symlink to best
â””â”€â”€ lstm/
    â””â”€â”€ v1.0.0/
```

### Metadata Example

```json
{
  "model_type": "xgboost",
  "version": "v1.0.1234567890",
  "trained_at": "2024-12-23T10:30:00Z",
  "training_samples": 6132,
  "features_count": 66,
  "metrics": {
    "rmse": 51.23,
    "mape": 3.21,
    "r2": 0.89
  }
}
```

---

## ğŸ”„ Adding New Models

### Step 1: Implement Model Class

```python
# models/lstm_model.py
from .base_model import BaseModel

class LSTMModel(BaseModel):
    def __init__(self, hyperparameters=None):
        super().__init__(model_type="lstm", hyperparameters=hyperparameters)
    
    def train(self, X_train, y_train, X_val=None, y_val=None):
        # LSTM training logic
        pass
    
    def predict(self, X, return_confidence=True):
        # LSTM prediction logic
        pass
    
    def get_feature_importance(self):
        # LSTM feature importance
        pass
```

### Step 2: Register in Factory

```python
# models/__init__.py
from .lstm_model import LSTMModel

# models/model_factory.py
ModelFactory.register_model('lstm', LSTMModel)
```

### Step 3: Use New Model

```python
# config.py
MODEL_TYPE = "lstm"
```

---

## ğŸ“Š Example Training Session

```bash
$ MODE=FULL_TRAIN python src/main.py

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         TRAINING SERVICE CONFIGURATION                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Mode: FULL_TRAIN
Model Type: xgboost
...

======================================================================
STEP 1: LOADING DATA
======================================================================
ğŸ“¥ Loading Gold data from S3...
  Found 3 parquet files
âœ… Loaded 8760 total rows
  Columns: 68
  Date range: 2021-01-01 to 2024-12-20

======================================================================
STEP 2: SPLITTING DATA
======================================================================
âœ‚ï¸ Splitting data (time-series)...
  Train: 6132 samples
  Val: 1314 samples
  Test: 1314 samples

======================================================================
STEP 3: TRAINING MODEL
======================================================================
ğŸŒ³ Training XGBoost model...
  Train samples: 6132
  Val samples: 1314
  âœ… Train RMSE: 45.23
  âœ… Val RMSE: 52.67
  âœ… Val MAPE: 3.45%

======================================================================
STEP 4: EVALUATION
======================================================================
ğŸ“Š Test Metrics:
  RMSE: 51.23
  MAPE: 3.21%
  MAE: 38.45
  R2: 0.89

ğŸ” Top 10 Features:
  temperature: 0.2453
  hour_sin: 0.1876
  day_of_week: 0.1234
  ...

======================================================================
STEP 5: SAVING MODEL
======================================================================
ğŸ’¾ Saving xgboost model version v1.0.1703345678...
  âœ… Saved model: models/xgboost/v1.0.1703345678/model.pkl
  âœ… Saved metadata: models/xgboost/v1.0.1703345678/metadata.json
  âœ… Saved metrics: models/xgboost/v1.0.1703345678/metrics.json
  âœ… Updated latest -> v1.0.1703345678

======================================================================
ğŸ‰ TRAINING COMPLETED
======================================================================
Model Type: xgboost
Version: v1.0.1703345678
Test RMSE: 51.23
Test MAPE: 3.21%
Duration: 127.3s
```

---

## ğŸ› Troubleshooting

### Issue: "Target column not found"

**Cause**: Mismatch giá»¯a config vÃ  Gold data

**Fix:**
```python
# config.py
TARGET_COLUMN = "electricity_demand"  # Check tÃªn cá»™t trong Gold data
```

### Issue: Memory Error

**Cause**: QuÃ¡ nhiá»u data

**Fix:**
- TÄƒng memory: 2 GB â†’ 4 GB
- Load data theo chunks
- Reduce features

### Issue: Poor metrics

**Fix:**
1. Check data quality
2. Tune hyperparameters
3. Add more features
4. Try different model

---

## ğŸ“ Next Steps

- âœ… **Deploy Training Service**
- âœ… **Monitor model performance**
- âœ… **Setup weekly retraining**
- ğŸ¨ **Build Dashboard Service**

---

## ğŸ“„ License

MIT License